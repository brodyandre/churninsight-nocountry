import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer

# 1. Definição de X (features) e y (alvo)
# Removemos IDs e colunas que não devem ser usadas no treino
X = df.drop(['customerID', 'Churn'], axis=1, errors='ignore')
y = df['Churn'].apply(lambda x: 1 if x == 'Yes' else 0) # Binário: 1 para Churn, 0 para Retenção

# 2. Identificação automática de colunas por tipo
categorical_cols = X.select_dtypes(include='object').columns
numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns

# 3. Construção do Transformador de Colunas
# Aplicamos OneHot para categorias e StandardScaler para números
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False, drop='first'), categorical_cols),
        ('num', StandardScaler(), numerical_cols)
    ])

# 4. Divisão Estratificada (Crucial para manter a proporção de Churn)
X_train_raw, X_test_raw, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.2, 
    random_state=42, 
    stratify=y
)

# 5. Ajuste e Transformação
# O 'fit' é feito APENAS no treino para evitar Data Leakage
X_train_processed = preprocessor.fit_transform(X_train_raw)
X_test_processed = preprocessor.transform(X_test_raw)

# 6. Reconstrução do DataFrame com os nomes reais das colunas
feature_names = preprocessor.get_feature_names_out()

X_train = pd.DataFrame(X_train_processed, columns=feature_names, index=X_train_raw.index)
X_test = pd.DataFrame(X_test_processed, columns=feature_names, index=X_test_raw.index)

print(f"✅ Pipeline de pré-processamento concluído!")
print(f"Total de features geradas: {len(feature_names)}")
print(f"Shape do treino: {X_train.shape}")
